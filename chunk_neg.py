import pandas as pd
import numpy as np
from tqdm import tqdm
import os
import time
import logging

# ì„¤ì •
chunk_size = 100000
n_chunks = 30
output_dir = "random_chunks"
os.makedirs(output_dir, exist_ok=True)

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(filename='log_random_chunk.txt', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# ë°ì´í„° ë¡œë“œ
parks = pd.read_csv("parks.csv")
cctv = pd.read_csv("cctv.csv")

# ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
def haversine_np(lon1, lat1, lon2, lat2):
    R = 6371000
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = np.sin(dlat / 2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon / 2)**2
    return 2 * R * np.arcsin(np.sqrt(a))

# ìƒì„± ì‹œì‘
np.random.seed(42)

for chunk_id in range(n_chunks):
    print(f"ğŸš§ ì²­í¬ {chunk_id} ì²˜ë¦¬ ì¤‘...")
    start = time.time()

    # ë¬´ì‘ìœ„ë¡œ ì£¼ì°¨ì¥ ìœ„ì¹˜ ì„ íƒ
    sampled_parks = parks.sample(n=chunk_size, replace=True).reset_index(drop=True)
    lat_offset = np.random.uniform(-0.0015, 0.0015, chunk_size)
    lon_offset = np.random.uniform(-0.0015, 0.0015, chunk_size)

    points = pd.DataFrame({
        'ìœ„ë„': sampled_parks['ìœ„ë„'] + lat_offset,
        'ê²½ë„': sampled_parks['ê²½ë„'] + lon_offset,
        'ìš”ì¼': np.random.choice(['Weekday', 'Saturday', 'Holiday'], size=chunk_size)
    })

    results = []

    for i in tqdm(range(chunk_size), desc=f"ì²­í¬ {chunk_id} ìƒì„± ì¤‘"):
        try:
            r_lat, r_lon = points.loc[i, 'ìœ„ë„'], points.loc[i, 'ê²½ë„']
            d_parks = haversine_np(r_lon, r_lat, parks['ê²½ë„'].values, parks['ìœ„ë„'].values)
            d_cctvs = haversine_np(r_lon, r_lat, cctv['ê²½ë„'].values, cctv['ìœ„ë„'].values)
            nearby_parks = parks[d_parks <= 300]

            def get_fee_hours(row):
                if row['í‰ì¼ìœ ë£Œ'] == 'Y':
                    return row['1ì‹œê°„ ìš”ê¸ˆ'], row['í‰ì¼ìš´ì˜ì‹œê°„']
                return 0, 0

            fee_hours = nearby_parks.apply(get_fee_hours, axis=1, result_type='expand')
            avg_fee = fee_hours[0].mean() if not fee_hours.empty else 0
            avg_hours = fee_hours[1].mean() if not fee_hours.empty else 0
            total_spaces = nearby_parks['ì´ì£¼ì°¨ë©´'].sum()
            cctv_count = np.sum(d_cctvs <= 300)

            results.append({
                'ì´ì£¼ì°¨ë©´ìˆ˜': total_spaces,
                'í‰ê· ìš”ê¸ˆ': avg_fee,
                'í‰ê· ìš´ì˜ì‹œê°„': avg_hours,
                'CCTVê°œìˆ˜': cctv_count,
                'ë¯¼ì›ë°œìƒ': 1,
                'ìœ„ë„': r_lat,      # âœ… ì¶”ê°€
                'ê²½ë„': r_lon       # âœ… ì¶”ê°€
            })

        except Exception as e:
            logging.error(f"[ì²­í¬ {chunk_id} index {i}] ì˜¤ë¥˜ ë°œìƒ: {e}")

    df_chunk = pd.DataFrame(results)
    df_chunk.to_csv(f"{output_dir}/negative_part_{chunk_id}.csv", index=False)
    print(f"âœ… ì²­í¬ {chunk_id} ì €ì¥ ì™„ë£Œ ({len(df_chunk)}ê°œ), ì†Œìš” ì‹œê°„: {time.time() - start:.2f}ì´ˆ")
