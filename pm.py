import pandas as pd
import glob
import logging
from tqdm import tqdm
from datetime import datetime
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder

# â± ì‹œì‘ ì‹œê° í‘œì‹œ
print("â± ì‹œì‘ ì‹œê°:", datetime.now().strftime("%H:%M:%S"))

# ğŸ“ ë¡œê·¸ íŒŒì¼ ì„¤ì •
logging.basicConfig(filename='log_pattern_mining.txt', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')
logging.info("íŒ¨í„´ ë§ˆì´ë‹ ì‹œì‘")

# ğŸ“ ë¯¼ì› ë°œìƒ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
positive_files = glob.glob("result_chunks/results_part_*.csv")
dfs = []

print(f"ğŸ“‚ ë¯¼ì› ë°œìƒ íŒŒì¼ {len(positive_files)}ê°œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
for file in tqdm(positive_files, desc="Loading"):
    try:
        df = pd.read_csv(file)
        dfs.append(df)
    except Exception as e:
        logging.error(f"íŒŒì¼ {file} ì½ê¸° ì‹¤íŒ¨: {e}")

# ğŸ”— ì „ì²´ ë³‘í•©
df = pd.concat(dfs, ignore_index=True)
logging.info(f"ì´ ë°ì´í„° ê°œìˆ˜: {len(df)}")

# âœ… í•„ìš”í•œ ë³€ìˆ˜ ì„ íƒ ë° ê²°ì¸¡ ì œê±°
cols = ['ì´ì£¼ì°¨ë©´ìˆ˜', 'í‰ê· ìš”ê¸ˆ', 'í‰ê· ìš´ì˜ì‹œê°„', 'CCTVê°œìˆ˜']
df = df[cols].dropna()
logging.info("ê²°ì¸¡ ì œê±° ì™„ë£Œ")

# â–¶ï¸ ë³€ìˆ˜ë³„ ì‚¬ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ì£¼í™”
df['ì£¼ì°¨ë©´_êµ¬ê°„'] = pd.qcut(df['ì´ì£¼ì°¨ë©´ìˆ˜'], q=4, labels=['ë§¤ìš°ì ìŒ', 'ì ìŒ', 'ë³´í†µ', 'ë§ìŒ'])
df['ìš”ê¸ˆ_êµ¬ê°„'] = pd.qcut(df['í‰ê· ìš”ê¸ˆ'], q=4, labels=['ë§¤ìš°ì €ë ´', 'ì €ë ´', 'ë³´í†µ', 'ë¹„ìŒˆ'])
df['ìš´ì˜ì‹œê°„_êµ¬ê°„'] = pd.qcut(df['í‰ê· ìš´ì˜ì‹œê°„'], q=4, labels=['ì§§ìŒ', 'ë³´í†µ', 'ê¹€', 'ë§¤ìš°ê¹€'])
df['CCTV_êµ¬ê°„'] = pd.qcut(df['CCTVê°œìˆ˜'], q=4, labels=['ì ìŒ', 'ë³´í†µ', 'ë§ìŒ', 'ë§¤ìš°ë§ìŒ'])
logging.info("ì‚¬ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ì£¼í™” ì™„ë£Œ")

# â–¶ï¸ íŠ¸ëœì­ì…˜ ë¦¬ìŠ¤íŠ¸ ìƒì„±
transactions = df[['ì£¼ì°¨ë©´_êµ¬ê°„', 'ìš”ê¸ˆ_êµ¬ê°„', 'ìš´ì˜ì‹œê°„_êµ¬ê°„', 'CCTV_êµ¬ê°„']].astype(str).values.tolist()
logging.info("íŠ¸ëœì­ì…˜ ë°ì´í„° ìƒì„± ì™„ë£Œ")

# â–¶ï¸ One-hot encoding
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_tf = pd.DataFrame(te_ary, columns=te.columns_)
logging.info("One-hot encoding ì™„ë£Œ")

# â–¶ï¸ Apriorië¡œ ë¹ˆë°œ í•­ëª©ì§‘í•© ì¶”ì¶œ
frequent_itemsets = apriori(df_tf, min_support=0.05, use_colnames=True)
logging.info(f"ë¹ˆë°œ í•­ëª©ì§‘í•© ê°œìˆ˜: {len(frequent_itemsets)}")

# â–¶ï¸ ì—°ê´€ ê·œì¹™ ì¶”ì¶œ
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1.2)
logging.info(f"ì¶”ì¶œëœ ì—°ê´€ ê·œì¹™ ìˆ˜: {len(rules)}")

# â–¶ï¸ ê²°ê³¼ ì €ì¥
rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].to_csv("pattern_mining_results.csv", index=False)
print("âœ… ì—°ê´€ ê·œì¹™ ì €ì¥ ì™„ë£Œ: pattern_mining_results.csv")
logging.info("ì—°ê´€ ê·œì¹™ ì €ì¥ ì™„ë£Œ")

print("â± ì¢…ë£Œ ì‹œê°:", datetime.now().strftime("%H:%M:%S"))
