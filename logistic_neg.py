import pandas as pd
import glob
import statsmodels.api as sm
import time
from datetime import datetime
import logging
from tqdm import tqdm

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(filename='log_logistic_all.txt', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

print("â± ì‹œì‘ ì‹œê°:", datetime.now().strftime("%H:%M:%S"))
start_all = time.time()

# ğŸ“ íŒŒì¼ ê²½ë¡œ ì„¤ì •
positive_files = glob.glob("results_chunks/results_part_*.csv")  # ê¸°ì¡´ ë¯¼ì›ë°œìƒ=1
negative_files = glob.glob("random_chunks/negative_part_*.csv")  # ìƒˆë¡œ ìƒì„±ëœ ë¯¼ì›ë°œìƒ=0

# ğŸ”„ ë°ì´í„° ë³‘í•©
dfs = []

print(f"ğŸ“‚ ë¯¼ì› ë°œìƒ íŒŒì¼ {len(positive_files)}ê°œ ë³‘í•© ì¤‘...")
for file in tqdm(positive_files, desc="Positive"):
    try:
        df = pd.read_csv(file)
        dfs.append(df)
    except Exception as e:
        logging.error(f"íŒŒì¼ {file} ì½ê¸° ì‹¤íŒ¨: {e}")

print(f"ğŸ“‚ ë¯¼ì› ì—†ìŒ íŒŒì¼ {len(negative_files)}ê°œ ë³‘í•© ì¤‘...")
for file in tqdm(negative_files, desc="Negative"):
    try:
        df = pd.read_csv(file)
        dfs.append(df)
    except Exception as e:
        logging.error(f"íŒŒì¼ {file} ì½ê¸° ì‹¤íŒ¨: {e}")

# ğŸ”— ì „ì²´ ë³‘í•©
full_df = pd.concat(dfs, ignore_index=True)
print(f"âœ… ì´ ë°ì´í„° ìˆ˜: {len(full_df)}")

# ğŸ§¹ ê²°ì¸¡ê°’ ì œê±°
clean_df = full_df.dropna()

# ğŸ¯ ë¡œì§€ìŠ¤í‹± íšŒê·€
X = clean_df[['ì´ì£¼ì°¨ë©´ìˆ˜', 'í‰ê· ìš”ê¸ˆ', 'í‰ê· ìš´ì˜ì‹œê°„', 'CCTVê°œìˆ˜']]
y = clean_df['ë¯¼ì›ë°œìƒ']
X = sm.add_constant(X)

print("ğŸ” ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¶„ì„ ì¤‘...")
try:
    model = sm.Logit(y, X).fit()
    print(model.summary())
except Exception as e:
    print(f"âš ï¸ íšŒê·€ ë¶„ì„ ì‹¤íŒ¨: {e}")
    logging.error(f"íšŒê·€ ë¶„ì„ ì‹¤íŒ¨: {e}")

end_all = time.time()
print("â± ì¢…ë£Œ ì‹œê°:", datetime.now().strftime("%H:%M:%S"))
print(f"âœ… ì „ì²´ ì†Œìš” ì‹œê°„: {end_all - start_all:.2f}ì´ˆ")
