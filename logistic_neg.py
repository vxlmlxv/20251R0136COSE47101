import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.preprocessing import StandardScaler
import glob
from tqdm import tqdm

# ğŸ“ label=1 (positive)ì™€ label=0 (negative) ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
positive_files = glob.glob("result_chunks_filtered/results_part_*.csv")
negative_files = glob.glob("result_chunks_label0/results_part_*.csv")

dfs = []
for file in tqdm(positive_files + negative_files, desc="CSV íŒŒì¼ ë³‘í•© ì¤‘"):
    try:
        df = pd.read_csv(file)
        dfs.append(df)
    except Exception as e:
        print(f"âŒ íŒŒì¼ {file} ì˜¤ë¥˜: {e}")

# ğŸ”— ì „ì²´ ë³‘í•©
full_df = pd.concat(dfs, ignore_index=True)

# ğŸ§¹ ê²°ì¸¡ì¹˜ ì œê±°
clean_df = full_df.dropna(subset=['ì´ì£¼ì°¨ë©´ìˆ˜', 'í‰ê· ìš”ê¸ˆ', 'í‰ê· ìš´ì˜ì‹œê°„', 'CCTVê°œìˆ˜', 'ë¯¼ì›ë°œìƒ'])

# â• interaction term ì¶”ê°€
clean_df['ìš”ê¸ˆ_CCTV'] = clean_df['í‰ê· ìš”ê¸ˆ'] * clean_df['CCTVê°œìˆ˜']
clean_df['ìš”ê¸ˆ_ë©´ìˆ˜'] = clean_df['í‰ê· ìš”ê¸ˆ'] * clean_df['ì´ì£¼ì°¨ë©´ìˆ˜']

# ğŸ¯ ë¡œì§€ìŠ¤í‹± íšŒê·€
feature_cols = [
    'ì´ì£¼ì°¨ë©´ìˆ˜', 'í‰ê· ìš”ê¸ˆ', 'í‰ê· ìš´ì˜ì‹œê°„', 'CCTVê°œìˆ˜',
    'ìš”ê¸ˆ_CCTV', 'ìš”ê¸ˆ_ë©´ìˆ˜'
]
X = clean_df[feature_cols]
y = clean_df['ë¯¼ì›ë°œìƒ']

scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
X_scaled = sm.add_constant(X_scaled)

print("ğŸ” ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¶„ì„ ì‹œì‘...")
model = sm.Logit(y, X_scaled)
result = model.fit()

# ğŸ“Š ê²°ê³¼ ì¶œë ¥
print(result.summary())
